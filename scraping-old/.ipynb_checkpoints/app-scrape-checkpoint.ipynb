{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Play and App Store\n",
    "\n",
    "In this notebook, we are going to perform scraping of the Google Play and iOS App Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Scraping to File\n",
    "\n",
    "We will first scrape the reviews and write them to CSV files.\n",
    "\n",
    "Prior to performing the operation, we have developed an App Scraper, which basically uses  [facundoolano](https://github.com/facundoolano \"facundoolano\")'s [Google Play Scraper](https://github.com/facundoolano/google-play-scraper \"Google Play Scraper\") and [App Store Scraper](https://github.com/facundoolano/app-store-scraper \"App Store Scraper\"). Because they have been developed on NodeJS, we use ExpressJS to convert them into REST APIs that can be taken advantage of by other applications such as this notebook.\n",
    "\n",
    "All codes in app scraping are developed on Docker containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "APP_NAME = ['ryde', 'tada', 'grab']\n",
    "\n",
    "APP_IDS = [\n",
    "    ['io.mvlchain.tada', 'com.rydesharing.ryde', 'com.grabtaxi.passenger'],\n",
    "    ['979806982', '1412329684', '647268330']\n",
    "]\n",
    "\n",
    "FS_PREFIX = ['play', 'appstore']\n",
    "\n",
    "URL_BASE = 'http://scraper:3000/api/'\n",
    "URL_REV = '/reviews?id='\n",
    "URL_PG = '&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_to_file(store, limit=150):\n",
    "    '''Writes the output from the scraping to individual CSV files\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    store : string\n",
    "        Define one of: 'play' or 'appstore'\n",
    "    limit : int\n",
    "        Restrict the number of times the URL to the app scraper is being called\n",
    "    '''\n",
    "    sid = FS_PREFIX.index(store)\n",
    "    start = 0 if sid == 0 else 1\n",
    "    \n",
    "    for app in APP_IDS[sid]:\n",
    "        p_dir = 'gp/' + app\n",
    "        print(p_dir)\n",
    "\n",
    "        # Make directory\n",
    "        if not os.path.exists(p_dir):\n",
    "            os.makedirs(p_dir)\n",
    "        \n",
    "        for i in range(start, limit):\n",
    "            # Form url\n",
    "            url = URL_BASE + store + URL_REV + app + URL_PG + str(i)\n",
    "            print(url)\n",
    "\n",
    "            # Read the output\n",
    "            df = pd.read_json(url)\n",
    "\n",
    "            # Put to file if more than 1 row\n",
    "            if len(df.index) != 0:\n",
    "                df.to_csv(p_dir + '/out' + str(i) + '.csv', index=False)\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gp/979806982\n",
      "http://scraper:3000/api/appstore/reviews?id=979806982&page=1\n",
      "http://scraper:3000/api/appstore/reviews?id=979806982&page=2\n",
      "gp/1412329684\n",
      "http://scraper:3000/api/appstore/reviews?id=1412329684&page=1\n",
      "http://scraper:3000/api/appstore/reviews?id=1412329684&page=2\n",
      "gp/647268330\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=1\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=2\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=3\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=4\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=5\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=6\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=7\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=8\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=9\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=10\n",
      "http://scraper:3000/api/appstore/reviews?id=647268330&page=11\n"
     ]
    }
   ],
   "source": [
    "# Srape iOS App Store\n",
    "scrape_to_file(FS_PREFIX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Srape Google Play Store\n",
    "scrape_to_file(FS_PREFIX[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidation\n",
    "\n",
    "The output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_files(store):\n",
    "    sid = FS_PREFIX.index(store)\n",
    "    \n",
    "    for index, app in enumerate(APP_IDS[sid]):\n",
    "        p_dir = 'gp/' + app + '/'\n",
    "        out_dir = 'out/'\n",
    "        \n",
    "        # Make directory\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        \n",
    "        print(p_dir, APP_NAME[index])\n",
    "        print(os.listdir(p_dir))\n",
    "        \n",
    "        out_file = out_dir + store + '_' + APP_NAME[index] + '.csv'\n",
    "        \n",
    "        # Combine the CSV files\n",
    "        combined_csv = pd.concat([pd.read_csv(p_dir + f) for f in os.listdir(p_dir)], sort=True)\n",
    "        combined_csv.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gp/io.mvlchain.tada/ ryde\n",
      "['out3.csv', 'out0.csv', 'out1.csv', 'out2.csv']\n",
      "gp/com.rydesharing.ryde/ tada\n",
      "['out3.csv', 'out11.csv', 'out16.csv', 'out13.csv', 'out0.csv', 'out10.csv', 'out9.csv', 'out14.csv', 'out12.csv', 'out5.csv', 'out6.csv', 'out1.csv', 'out17.csv', 'out2.csv', 'out8.csv', 'out15.csv', 'out4.csv', 'out7.csv', 'out18.csv']\n",
      "gp/com.grabtaxi.passenger/ grab\n",
      "['out3.csv', 'out107.csv', 'out20.csv', 'out110.csv', 'out11.csv', 'out28.csv', 'out25.csv', 'out109.csv', 'out93.csv', 'out90.csv', 'out104.csv', 'out81.csv', 'out79.csv', 'out50.csv', 'out16.csv', 'out33.csv', 'out108.csv', 'out61.csv', 'out40.csv', 'out71.csv', 'out30.csv', 'out35.csv', 'out13.csv', 'out73.csv', 'out106.csv', 'out49.csv', 'out21.csv', 'out39.csv', 'out89.csv', 'out82.csv', 'out0.csv', 'out26.csv', 'out37.csv', 'out34.csv', 'out92.csv', 'out70.csv', 'out98.csv', 'out51.csv', 'out19.csv', 'out60.csv', 'out69.csv', 'out10.csv', 'out47.csv', 'out9.csv', 'out64.csv', 'out36.csv', 'out97.csv', 'out85.csv', 'out14.csv', 'out12.csv', 'out99.csv', 'out58.csv', 'out74.csv', 'out5.csv', 'out53.csv', 'out62.csv', 'out23.csv', 'out52.csv', 'out54.csv', 'out66.csv', 'out46.csv', 'out57.csv', 'out95.csv', 'out22.csv', 'out78.csv', 'out83.csv', 'out77.csv', 'out6.csv', 'out44.csv', 'out1.csv', 'out17.csv', 'out100.csv', 'out38.csv', 'out75.csv', 'out91.csv', 'out31.csv', 'out103.csv', 'out59.csv', 'out101.csv', 'out56.csv', 'out94.csv', 'out2.csv', 'out102.csv', 'out86.csv', 'out87.csv', 'out29.csv', 'out72.csv', 'out111.csv', 'out8.csv', 'out84.csv', 'out65.csv', 'out48.csv', 'out68.csv', 'out105.csv', 'out67.csv', 'out27.csv', 'out24.csv', 'out32.csv', 'out41.csv', 'out88.csv', 'out76.csv', 'out43.csv', 'out15.csv', 'out4.csv', 'out55.csv', 'out63.csv', 'out7.csv', 'out42.csv', 'out96.csv', 'out45.csv', 'out80.csv', 'out18.csv']\n",
      "gp/979806982/ ryde\n",
      "['out1.csv']\n",
      "gp/1412329684/ tada\n",
      "['out1.csv']\n",
      "gp/647268330/ grab\n",
      "['out3.csv', 'out10.csv', 'out9.csv', 'out5.csv', 'out6.csv', 'out1.csv', 'out2.csv', 'out8.csv', 'out4.csv', 'out7.csv']\n"
     ]
    }
   ],
   "source": [
    "for s in FS_PREFIX:\n",
    "    consolidate_files(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('gp'):\n",
    "    os.removedirs('gp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
